{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c686ed5d-9f52-42d6-89f2-aa000ec65f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s5/t_508rpn255685tj87wvvxrc0000gn/T/ipykernel_6571/3918657540.py:23: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_train = pd.read_csv(train_url, delim_whitespace=True, names=names, na_values='?')\n",
      "/var/folders/s5/t_508rpn255685tj87wvvxrc0000gn/T/ipykernel_6571/3918657540.py:24: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_test = pd.read_csv(test_url, delim_whitespace=True, names=names, na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean dataset created and saved as 'horse_colic_preprocessed.csv'\n",
      "Shape: (368, 23)\n",
      "    surgery       age  rectal_temperature     pulse  respiratory_rate  \\\n",
      "0  1.192079 -0.286972            0.580749 -0.147068         -0.128183   \n",
      "1 -0.838870 -0.286972            1.673525  0.662354         -0.632014   \n",
      "2  1.192079 -0.286972            0.268528 -1.103657         -0.380099   \n",
      "3 -0.838870  3.484660            1.517414  3.458537          3.398639   \n",
      "4  1.192079 -0.286972           -1.292581  1.251024          0.312670   \n",
      "\n",
      "   temperature_extremities  peripheral_pulse  mucous_membranes  \\\n",
      "0                 0.543602          1.245342          0.097113   \n",
      "1                 0.543602         -0.738579          0.771410   \n",
      "2                -1.508146         -0.738579          0.097113   \n",
      "3                 1.569476         -0.738579          2.120004   \n",
      "4                 0.543602         -0.738579          2.120004   \n",
      "\n",
      "   capillary_refill_time      pain  ...  nasogastric_reflux  \\\n",
      "0               1.593883  1.750085  ...           -0.547419   \n",
      "1              -0.594733  0.064139  ...           -0.547419   \n",
      "2              -0.594733  0.064139  ...           -0.547419   \n",
      "3               1.593883 -0.778834  ...            0.861323   \n",
      "4               1.593883  0.064139  ...           -0.547419   \n",
      "\n",
      "   nasogastric_reflux_ph     feces   abdomen  packed_cell_volume  \\\n",
      "0               0.093449  0.142601  1.029085           -0.047587   \n",
      "1               0.093449  1.132740 -1.600799            0.437782   \n",
      "2               0.093449 -1.837676 -2.477427           -1.212473   \n",
      "3              -0.362038  0.142601  0.152457            0.243634   \n",
      "4               0.093449  0.142601  0.152457            2.767554   \n",
      "\n",
      "   total_protein  abdomcentesis_appearance  abdomcentesis_total_protein  \\\n",
      "0      -0.539964                 -0.039436                    -0.250436   \n",
      "1       2.341754                 -0.039436                    -0.332139   \n",
      "2      -0.603919                 -0.039436                    -0.250436   \n",
      "3      -0.585109                  1.774627                     2.364048   \n",
      "4      -0.577585                 -0.039436                    -0.250436   \n",
      "\n",
      "    outcome  surgical_lesion  \n",
      "0  0.651974                0  \n",
      "1  2.022981                0  \n",
      "2 -0.719034                0  \n",
      "3  0.651974                1  \n",
      "4  0.651974                0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Data\n",
    "# -------------------------------\n",
    "train_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.data\"\n",
    "test_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/horse-colic/horse-colic.test\"\n",
    "\n",
    "names = [\n",
    "    \"surgery\", \"age\", \"hospital_number\", \"rectal_temperature\", \"pulse\", \"respiratory_rate\",\n",
    "    \"temperature_extremities\", \"peripheral_pulse\", \"mucous_membranes\", \"capillary_refill_time\",\n",
    "    \"pain\", \"peristalsis\", \"abdominal_distension\", \"nasogastric_tube\", \"nasogastric_reflux\",\n",
    "    \"nasogastric_reflux_ph\", \"feces\", \"abdomen\", \"packed_cell_volume\", \"total_protein\",\n",
    "    \"abdomcentesis_appearance\", \"abdomcentesis_total_protein\", \"outcome\", \"surgical_lesion\",\n",
    "    \"lesion_1\", \"lesion_2\", \"lesion_3\", \"cp_data\"\n",
    "]\n",
    "\n",
    "df_train = pd.read_csv(train_url, delim_whitespace=True, names=names, na_values='?')\n",
    "df_test = pd.read_csv(test_url, delim_whitespace=True, names=names, na_values='?')\n",
    "\n",
    "df = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Drop unneeded columns\n",
    "# -------------------------------\n",
    "df.drop(columns=[\"hospital_number\", \"lesion_1\", \"lesion_2\", \"lesion_3\", \"cp_data\"], inplace=True)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Clean target column\n",
    "# -------------------------------\n",
    "df = df[~df[\"surgical_lesion\"].isna()]\n",
    "df[\"surgical_lesion\"] = df[\"surgical_lesion\"].map({1: 1, 2: 0})\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Separate X, y\n",
    "# -------------------------------\n",
    "X = df.drop(\"surgical_lesion\", axis=1)\n",
    "y = df[\"surgical_lesion\"]\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Detect column types\n",
    "# -------------------------------\n",
    "numeric_feats = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_feats = [c for c in X.columns if c not in numeric_feats]\n",
    "\n",
    "# If no categorical columns are found, skip encoding safely\n",
    "if len(categorical_feats) == 0:\n",
    "    categorical_feats = []\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Build pipeline\n",
    "# -------------------------------\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_feats),\n",
    "        (\"cat\", categorical_transformer, categorical_feats)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Fit and transform\n",
    "# -------------------------------\n",
    "X_proc = preprocessor.fit_transform(X)\n",
    "\n",
    "# Safely access the encoder only if categorical columns exist\n",
    "if len(categorical_feats) > 0:\n",
    "    encoder = preprocessor.named_transformers_[\"cat\"].named_steps[\"encoder\"]\n",
    "    cat_cols = encoder.get_feature_names_out(categorical_feats)\n",
    "else:\n",
    "    cat_cols = []\n",
    "\n",
    "# Merge numeric + encoded column names\n",
    "all_cols = numeric_feats + list(cat_cols)\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Build DataFrame and Save\n",
    "# -------------------------------\n",
    "X_proc = np.array(X_proc)\n",
    "df_processed = pd.DataFrame(X_proc, columns=all_cols)\n",
    "df_processed[\"surgical_lesion\"] = y.values\n",
    "\n",
    "df_processed.to_csv(\"horse_colic_preprocessed.csv\", index=False)\n",
    "print(\"✅ Clean dataset created and saved as 'horse_colic_preprocessed.csv'\")\n",
    "print(\"Shape:\", df_processed.shape)\n",
    "print(df_processed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c63c19-573b-48ec-a314-ce405f437fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dwh)",
   "language": "python",
   "name": "dwh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
